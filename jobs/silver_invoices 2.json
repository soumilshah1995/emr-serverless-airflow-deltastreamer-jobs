{
  "jar": [
    "/usr/lib/hudi/hudi-utilities-bundle.jar"
  ],
  "spark_submit_parameters": [
    "--conf spark.serializer=org.apache.spark.serializer.KryoSerializer",
    "--conf spark.sql.extensions=org.apache.spark.sql.hudi.HoodieSparkSessionExtension",
    "--conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.hudi.catalog.HoodieCatalog",
    "--conf spark.sql.hive.convertMetastoreParquet=false",
    "--conf mapreduce.fileoutputcommitter.marksuccessfuljobs=false",
    "--conf spark.hadoop.hive.metastore.client.factory.class=com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory",
    "--class org.apache.hudi.utilities.deltastreamer.HoodieDeltaStreamer"
  ],
  "arguments": {
    "table-type": "COPY_ON_WRITE",
    "op": "UPSERT",
    "source-ordering-field": "replicadmstimestamp",
    "source-class": "org.apache.hudi.utilities.sources.HoodieIncrSource",
    "target-table": "invoice",
    "target-base-path": "s3://<BUCKET>/zone=silver/invoices",
    "hoodie-conf": {
      "hoodie.streamer.source.hoodieincr.path": "s3://<BUCKET>/zone=bronze/invoices",
      "hoodie.streamer.source.hoodieincr.missing.checkpoint.strategy": "READ_UPTO_LATEST_COMMIT",
      "hoodie.datasource.write.recordkey.field": "invoiceid",
      "hoodie.datasource.write.partitionpath.field": "destinationstate",
      "hoodie.datasource.write.precombine.field": "replicadmstimestamp"
    }
  },
  "job": {
    "job_name": "delta_streamer_silver_invoice",
    "created_by": "Soumil Shah",
    "created_at": "2024-03-20",
    "ApplicationId": "XX",
    "ExecutionTime": 600,
    "JobActive": "true",
    "schedule": "@daily",
    "JobStatusPolling": "true",
    "JobDescription": "Ingest data from parquet source",
    "ExecutionArn": "<>"
  }
}